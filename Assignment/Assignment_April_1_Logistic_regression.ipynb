{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpsUZVCcNC9Zs7kJQjf9Iq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate.\n",
        "\n",
        "Linear regression is used to predict a continuos value while Logistic regression is used fro the task that involves predicting categorical value.\n",
        "\n",
        "If we want to predict whether a patient has diabetes or not based on the medical conditions,logistic regression can be used."
      ],
      "metadata": {
        "id": "g_tE9TlgqHMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
        "\n",
        "`cost = -1/m * (y_act*log(y_pred) + (1-y_act) * log(1 - y_pred))`\n",
        "\n",
        "`m - number of training examples`\n",
        "\n",
        "`y_act - vector of actual labels`\n",
        "\n",
        "`y_pred - vector of predicted value`\n",
        "\n",
        "cost function in logistic regerssion is optimized using the iterate algorithm called gradient descent."
      ],
      "metadata": {
        "id": "aHCzo5HoqHKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
        "\n",
        "Regularization is a technique that modifies the learning algorithm such that the generaliztion error is reduced which helps prevent overfitting. One way to use regularization in logistic regression is to use regularization term in loss function which the algorithm tries to minimize. The regularization term penalizes large coefficients towards zero. Therefore, the impact of features on model's performace is minimized."
      ],
      "metadata": {
        "id": "ypGGYfapqHHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
        "\n",
        "In simpler terms, the ROC curve shows how well a classifier can distinguish between positive and negative examples, given different thresholds. The higher the AUC, the better the classifier is at distinguishing between positive and negative examples."
      ],
      "metadata": {
        "id": "nyP3Oy4xqHEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
        "\n",
        "* Filter methods: These methods select features based on a statistical measure of their importance.\n",
        "\n",
        "* Wrapper methods: These methods select features by iteratively adding or removing features from the model and evaluating the performance of the model.\n",
        "\n",
        "* Embedded methods: These methods select features as part of the model training process. For example, Lasso regression is a penalized regression model that shrinks the coefficients of less important features to zero.\n",
        "\n",
        "feature selection helps model performance in the following way,\n",
        "\n",
        "    - it can reduce the dimension of the problem,therfore, noises in the data can be removed which can make the model efficient."
      ],
      "metadata": {
        "id": "eousfc8GqHBp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
        "\n",
        "The problem with imbalanced dataset can be solved in the follwoing ways,\n",
        "\n",
        "1. Upsampling - here the size of minority dataset in increased with techinuques such as SMOTE and random upsampling.\n",
        "2. Downsampling - here the size of the majority datast is reduced such the the ratio between data points in different classes are equal."
      ],
      "metadata": {
        "id": "LPZwPpi9qG_I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example what can be done if there is multicollinearity among the independent variables?\n",
        "\n",
        "1. Overfitting - it happens when the model is too complex and learns noises in the training data. Therefore, the model can not be generalize well to new data. This can be addressed with adding regularization term, reducing the number of independent variables.\n",
        "\n",
        "2. Underfitting - it happens when the modle is much simpler such that it can not learn patterns in the training data such that it can not be generalized well to the new data. The can be addressed by increasing number of independent features and reducing the amount of data.\n",
        "\n",
        "3. Multicollinearity - it is the case when independent features are correlated with each other. This makes the model difficult for determining which feature is actually affecting the dependent feature. This can be solved by removing one feature out of correlated features.\n",
        "\n",
        "4. Non-linearity - logistic regeression assumes that the relationship betwee the independent features and dependent feature is linear. However, when it is not the case, the problem of non-linearity occurs. To prevent this, independent feature can be transformed into a format such that linearity is maintained.\n",
        "\n",
        "5. Imbalanced dataset - it happens when the ratio between number of data points in different categories is different. This can be solved by techniques such as upsampling and downsampling."
      ],
      "metadata": {
        "id": "nBy4mcv1qG8t"
      }
    }
  ]
}