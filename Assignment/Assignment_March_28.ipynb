{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?"
      ],
      "metadata": {
        "id": "HLIywNKZ1b-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge regression is a type of regression used to reduce overfitting. In contrast to ordinary least square regression, which does not penalizes the cost function, ridge regression penalizes the cost function to shrinks the cofficients towards zero."
      ],
      "metadata": {
        "id": "i8U-5xKm1cAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. What are the assumptions of Ridge Regression?"
      ],
      "metadata": {
        "id": "BoFdrBNp1cDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linearity, constant variance, independence, normality of errors, independence of errors, homoscedasticity, number of predictors should be less than the observations."
      ],
      "metadata": {
        "id": "khrPohMa1cFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
      ],
      "metadata": {
        "id": "LOE_8tTw1cIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the value of lambda is very low, the penalty terms have very minimal or no effect on the cost function, resulting in low bias and high variance. Similarly, when it is higher, it penalizes the cost function more, resulting in low variance and high bias. Therefore, in both cases, when lambda is very high and very low, the error of test data increases. Therefore, it is important to select an optimum value of lambda which maintains trade-off between bias and variance. Using cross validation methods, the best value for the lambda can be determined."
      ],
      "metadata": {
        "id": "kpp01STK1cKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q4. Can Ridge Regression be used for feature selection? If yes, how?"
      ],
      "metadata": {
        "id": "AbXbSPk31cNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Ridge regression can be used for the feature selection. It penalizes the cost function such that the coffients are shrinked. However, it does not do the feature selection as other methods do by setting the cofficients of the features to zero. However, after finding the optimal lambda value, which reduces the validation loss, with cross validation method or any other methods, features with low absolute value of cofficient can be eliminated."
      ],
      "metadata": {
        "id": "vGyL4t7K1cPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
      ],
      "metadata": {
        "id": "QmVNEdz81cSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It performs well in the presence of multicollinearity as it shrinks the cofficients close to zero. Therefore, sensitivity of the model to the change in data reduces and more stable estimate can be obtained."
      ],
      "metadata": {
        "id": "7fFIecnU157R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
      ],
      "metadata": {
        "id": "hgEua1bP16Cs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes"
      ],
      "metadata": {
        "id": "L3_SUV6716Fq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q7. How do you interpret the coefficients of Ridge Regression?"
      ],
      "metadata": {
        "id": "ENC6dquZ16IB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coefficint of features determines the importance of each feature in prediction. If a feature has a very low coefficient, it is less useful for the prediction. Similarly, when the coefficient is high, the corresponsing features play an important role in the prediction."
      ],
      "metadata": {
        "id": "H8PfVgl_16K5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
      ],
      "metadata": {
        "id": "9inBJ2oK2S-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes it is possible to use ridge regression for the time-series data by making the data stationary and standardized"
      ],
      "metadata": {
        "id": "ifpWKrr_2Ryl"
      }
    }
  ]
}