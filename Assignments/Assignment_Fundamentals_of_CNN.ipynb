{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUNzkUJ3NK1+jB7eG1K3dE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fundamentals of CNN"
      ],
      "metadata": {
        "id": "XB-M2f4Gar1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Difference between Object Detection and Objcet Classification.\n",
        "### a. Explain the difference between object detection and object classification in the context of computer vision tasks. Provide examples to illustrate each concept.\n",
        "\n",
        "Object classification only tells about whether a particular object present in the image or not. However, object detection, on the other hand, tells the spatial information of an object in addition to identifying the object in the image even multiple objects of same class are there.\n",
        "\n",
        "Example, if a model trained on pictures of animals tells whether a particular animal exist on the image or not, it is a image classification problem. However, if a model tells, what type of animals are present in the image including their location on the image, it is called object detection."
      ],
      "metadata": {
        "id": "o_dxKLcHJZOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Scenarios where Object Detection is used:\n",
        "### a. Describe at least three scenarios or real-world applications where object detection techniques are commonly used. Explain the significance of object detection in these scenarios and how it benefits the respective applications.\n",
        "\n",
        "* Autonomous vehicles\n",
        "* Traffic cameras\n",
        "* Medical imaging.\n",
        "\n",
        "In the above scenarious, object detection algorithms needs to detect multiple objects including the spatial information. For example, in medical imaging, a detection algorithm must identify object of interest, eg tumor, including the location of it."
      ],
      "metadata": {
        "id": "KZwEoTqtJZLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Image Data as Structured Data:\n",
        "### a. Discuss whether image data can be considered a structured form of data. Provide reasoning and examples to support your answer.\n",
        "\n",
        "Image is considered unstructured data because of the following reasons,\n",
        "* it does not have a proper shape and resolution.\n",
        "* it might have a wide range of content, different objects, texts, and numbers.\n",
        "* it might be in a different color scale, gray scale image or color image."
      ],
      "metadata": {
        "id": "kgLhD5vbJZJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Explainig Information ia an Image for CNN:\n",
        "### a. Explain how Convolutional Neural Networks (CNN) can extract and understand information from an image. Discuss the key components and processes involved in analyzing image data using CNNs.\n",
        "\n",
        "An image is made up of pixels, each of which is assigned a numerical value depending on its brightness. In order for algorithms to extract information from an image, they need to identify the variation of pixel values in the image. This is done using a concept known as filters. Filters are associated with weights, which are learned automatically by the neural network using backpropagation. The algorithm slides multiple filters, depending on the context, over the image and extracts features, known as feature maps, by taking the dot product of the filter and the pixel values in the image, followed by an activation function. The algorithm then moves the filter to a different position and repeats the process until it has tiled the entire image. To remove unwanted features and noise from the feature maps, a pooling operation is performed. This step is repeated for a desired number of times. Here, feature maps are getting more abstract information with number of covolutional operations. Finally, the feature maps are flattened and given to the deep neural network model for tasks such as regression and classification."
      ],
      "metadata": {
        "id": "0dDw0d5TJZGm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Flattenig Images for ANN:\n",
        "### a. Discuss why it is not recommended to flatten images directly and input them into an Artificial Neural Network (ANN) for image classification. Highlight the limitations and challenges associated with this approach.\n",
        "\n",
        "An image might have multiple objects, once it is flattened the spatial information might be lost, making it more difficult for the tasks like object detection and classification. At the same time, flattening of image of large mega pixel results in large size vecotor. This creates a not of learnable parameters making the model too complecated. At the same time, it costs a lot of computational resources and time."
      ],
      "metadata": {
        "id": "46ukmnDbJZCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Applyig CNN to the MNIST Dataset:\n",
        "### a. Explain why it is not necessary to apply CNN to the MNIST dataset for image classification. Discuss the characteristics of the MNIST dataset and how it aligns with the requirements of CNNs.\n",
        "\n",
        "Images in MNISt dataset are 28 X 28 pixel grayscale images of hand written digits. Therefore, it requires that the algorithm to detect only what type of hand written digit is present in the image, not spatial information. Therefore, the image can be flatten can passed into the dense layer for the classification task. Therefore, it is not necessary to apply CNN to this dataset."
      ],
      "metadata": {
        "id": "Gv5PRWFiJZAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Extracting Features at Local Space:\n",
        "### a. Justify why it is important to extract features from an image at the local level rather than considering the entire image as a whole. Discuss the advantages and insights gained by performing local feature extraction.\n",
        "\n",
        "Local feature extraction is important in image understanding because it allows us to extract features from the image at the local level, which are more robust to noise and changes in illumination, more discriminative, and can be used to represent the image at different levels of abstraction. This makes them more suitable for tasks such as image classification, object detection, and image segmentation."
      ],
      "metadata": {
        "id": "k1q_CGKTYhfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Importace of Covolution and Max Poolig:\n",
        "### a. Elaborate on the importance of convolution and max pooling operations in a Convolutional Neural Network (CNN). Explain how these operations contribute to feature extraction and spatial down-sampling in CNNs.\n",
        "\n",
        "Convolution is an operation that takes a small region of the input image, called a kernel, and slides it over the image, computing the dot product of the kernel and the image at each location. The output of the convolution operation is called a feature map.\n",
        "\n",
        "Max pooling is an operation that downsamples the feature maps by taking the maximum value from each region of the feature map. This reduces the dimensionality of the feature maps, which can help to prevent overfitting."
      ],
      "metadata": {
        "id": "crUcZc7UYhcv"
      }
    }
  ]
}