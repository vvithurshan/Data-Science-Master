{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a87b81e-dff3-4992-8366-fb45a7cb4cfe",
   "metadata": {},
   "source": [
    "## Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45334dea-8a0a-4c52-989c-31dbd0cf6e03",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model is too complex and captures noise in the data rather than the underlying patterns.\n",
    "Due to overfitting, model will not be able to generalize well to new data, and it may perform poorly on test dataset.\n",
    "Underfitting occurs when a model is too simple and does not capture the underlying patterns in the data.\n",
    "Due to underfitting, the model will not capture the underlying patterns in the data, and it may not perform well on both train and test data.\n",
    "\n",
    "To overcome this, techniques such as regularization, early stopping, or increasing the amount of train data can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd95a0e-97ba-4cc0-bda3-b5967daf7be7",
   "metadata": {},
   "source": [
    "## Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae2725-40ae-4869-a689-bcba64ca1c05",
   "metadata": {},
   "source": [
    "1. Increase the amount of data will help the model generalize better.\n",
    "2. Simplify the model architecture - implifying the architecture of the model by reducing the number of layers or number of neurons can prevent overfitting.\n",
    "3. Early stopping - stop the training process when vadidation error starts increasing.\n",
    "4. Regularization: Regularization adds a penalty term to the loss function to prevent the model from overemphasizing the importance of certain features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce079f68-8996-46bd-bc09-2f1a59d17bfe",
   "metadata": {},
   "source": [
    "## Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2aac2-de9a-4cd3-9f70-b3040f829ebf",
   "metadata": {},
   "source": [
    "Underfitting is the situation when the model is too simple to capture the underlying patterns in the dataset.\n",
    "\n",
    "It can occur for the following reasons\n",
    "1. When the data size is too small.\n",
    "2. When the model is too simple.\n",
    "3. When features are not informative enough to the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8a1be8-e0ae-47ad-ada0-46954e7bc4dc",
   "metadata": {},
   "source": [
    "## Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6812a62-9296-4682-836c-f174adc1a7d5",
   "metadata": {},
   "source": [
    "Bias-variance tradeoff explains the relationship between the bias and variance of the model and its performace.Bias refers to the difference between the prediction of the model and the target variable. High bias occurs when a model is too simple and cannot capture the complexity of the dataset, it is knows as underfitting.\n",
    "Variance refers to the variability of the model's prediction for different training dataset. High variance occurs when a model is too complex and can fit the noise in the training data, resulting in significant overfitting.\n",
    "\n",
    "The tradeoff between bias and variance is essential. Because, reducing one lead to the increase in other one. Therefore, to achieve optimal model performace, it is important to maintain the balance between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e884e29b-854e-4393-bb84-5ddb24fa7cc1",
   "metadata": {},
   "source": [
    "## Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba21730-b143-42af-bcc4-ff0d7c85e852",
   "metadata": {},
   "source": [
    "methods to detect overfitting and underfitting\n",
    "1. Cross-validation - it involves dividing the dataset into mutiple subsets and training the model on different subsets while evaluating it on the remaining dataset. The allows one to check the performace of the model on different dataset. Therefore, overfitting and underfitting can be detected.\n",
    "2. Learning curves - it shows the relationship between the training size and the model performance. Therefore, by plotting learning curve over/under fitting can be detected.\n",
    "\n",
    "To determine whether a model is overfitting or underfitting, we can look at the performance metrics such as accuracy, precision, recall, and F1 score. If the model has high training accuracy but low validation accuracy, it is likely overfitting. On the other hand, if the model has low training accuracy and low validation accuracy, it is likely underfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1684fd-2807-4c4e-a806-d2b1432aba9c",
   "metadata": {},
   "source": [
    "## Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef713ee-ed45-452f-a6de-d64426c014b3",
   "metadata": {},
   "source": [
    "Bias refers to the degree of inaccuracy in the model's predictions, while variance refers to the degree of variability to small fluctuations in the training data.\n",
    "\n",
    "A high bias model is one that is too simple and has not learned the underlying patterns in the data. This results in underfitting, where the model is unable to capture the complexity of the data and makes large errors in both the training and test sets. An example of a high bias model is a linear regression model used to fit a nonlinear dataset.\n",
    "\n",
    "On the other hand, a high variance model is one that is too complex and has overfit the training data. This results in the model fitting to the noise in the data rather than the underlying patterns. An example of a high variance model is a decision tree with too many branches or depth, resulting in a model that is too complex and overfits the training data.\n",
    "\n",
    "The bias-variance tradeoff is the balancing act between the two sources of error. Ideally, we want to achieve a low bias and a low variance model. In practice, this is often not possible, and we need to make tradeoffs between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2339c36-6876-482e-a81f-fd983cae7bc9",
   "metadata": {},
   "source": [
    "## Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5674848-1fd4-47c9-a4db-1f552f90d27e",
   "metadata": {},
   "source": [
    "Regularization is a techniuqe used to prevent overfitting by adding penalty term to the loss function. This penalty term encourages the model to have smaller weights. Therefore, it reduces the complexity of the model.\n",
    "\n",
    "1. L1 regularization - it adds a penalty term proportional to the absolute value of the weights. It encourages sparsity in the model by setting some weights to zero.\n",
    "\n",
    "2. L2 regularization - it adds a penalty term proportional to the square of the weights. It encourages smaller weights and is less likely to set any weights to zero.\n",
    "\n",
    "3. Elastic net regularization: it combines L1 and L2 regularization by adding a penalty term that is a linear combination of the L1 and L2 penalty terms.\n",
    "\n",
    "4. Dropout regularization: it randomly drops out (sets to zero) some of the nodes in a neural network during training, forcing the network to learn more robust and generalized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fcb10-012c-4ad4-9056-fc62d840fcab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
