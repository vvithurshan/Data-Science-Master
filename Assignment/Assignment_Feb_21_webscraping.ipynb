{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0df9a16-4108-4332-941b-f7c0af2d073a",
   "metadata": {},
   "source": [
    "# Assignment Webscraping "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfb9ff8-02ef-4005-993a-14feea53d1d5",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195674a-1af3-415c-9fd0-598db02949ee",
   "metadata": {},
   "source": [
    "Web scraping is the process of accessing data such as image, text, links, and structured data with the help of software tools.\n",
    "\n",
    "Web scraping is used in the following purposes\n",
    "1. Data collection - for reseach and analysis purposes a lot of data from multiple web sites need to be collected. However, accessing all the data manually cost a lot of time. Therefore, web scraping is used to access those data.\n",
    "\n",
    "2. Data aggregation - it is used to aggregate data such as news and weather report from multiple web sites into one web page. \n",
    "\n",
    "3. Real time tracking of events - It is used to track the changes of content such as product price, strock price, resources availability.\n",
    "\n",
    "Fields\n",
    "1. Research and analysis.\n",
    "2. E-commerce.\n",
    "3. Finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa43d66-9084-4f29-b41d-8efea013e4b3",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b64962-c87b-4e68-b678-15700458bbf2",
   "metadata": {},
   "source": [
    "1. Manual web scraping,\n",
    "2. Web scraping with the help of web scraping tools.\n",
    "3. Web scraping with the help of APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2df4c-d748-4fb4-ab8c-0edc7fa47ec8",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4b1fb-da13-4fa1-b82a-8aa0e597c806",
   "metadata": {},
   "source": [
    "Beautiful soup is a python library used for web scraping by providing efficient way to parse documents such as HTML and XML and extract data. \n",
    "\n",
    "It is used for web scraping for the following reasons. \n",
    "1. It provides user-friendly interface for web scraping.\n",
    "2. It handles poorly designed documents by automatically detecting faults and correcting them.\n",
    "3. It can be integrated with other python libraries such as flask, pandas, matplotlib, and HTTP requests.\n",
    "4. With the help of powerful searching and filtering options, develeopers are able to do web scraping easily.\n",
    "5. It is an open source, allowing other developers to contribute to its development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0dc1f0-49a5-469e-89f0-deabfb9e59fb",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aed51a-d002-4422-b902-234f81c48163",
   "metadata": {},
   "source": [
    "1. Flask can easily integrated with Beautiful soup. Therefore, Beautilful soup can be used to parse HTML and XML documents and extract from them.\n",
    "\n",
    "2. Flask provies user-friendly interface. Therefore, web scraping can be done with the help of user-friendly interface. \n",
    "\n",
    "3. With the help of template rendering functionality provided by flask, scrapted data can be displayed in a user-friendly interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e899f90-afe8-4774-972e-5c701ca1db19",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b958557-4517-403f-88eb-f8bd89836395",
   "metadata": {},
   "source": [
    "1. AWS code pipeline - It is used to automate the code changes and update in a simple and sclable way. (In this project, it was used to connect the data in the github repository to the AWS Beanstalk)\n",
    "\n",
    "2. AWS Beanstalk - It provides the infrastructure and resources needed to deploy web applications and services in a fast and sclable way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
